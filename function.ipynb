{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis by Speech\n",
    "### Q1. What is this Project ?\n",
    "- Ans. In this Project User can calculated sentiment score of any statement. (Positive/ Negative/ Neutral)\n",
    "### Q2. How it works ?\n",
    "- Ans.  After run this program user has to speak anything (English), after finishing the statement it will automatically calculate sentiment score and category of the statement. \n",
    "- sentiment score varies between -1 to +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_text = \"This is a am are she he it name very be being #$ & !! () * good movie everyone should watch #sholay @Pawan Yadav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning and sentiment calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What this function does ?\n",
    "# This function converts audio to text then after conversion of audio in text form it will clean the text like..\n",
    "# lowers the sentence remove punctuations, remove stop words then finally calculate the sentiment score using textblob\n",
    "\n",
    "def Pawan_sentiment_calculator(audio_text): # taking argument string\n",
    "    input_text = audio_text\n",
    "    input_text_blob = TextBlob(input_text)  # conversion of srting into textblob type\n",
    "    input_text_lower = input_text_blob.lower() # Lowering all string\n",
    "    input_text_lower = str(input_text_lower) # again converting to string because tokenization requires string as input\n",
    "    \n",
    "    input_text_remove_stpwrds = []   # initializing a list to store words after cleaning\n",
    "\n",
    "#     print(input_text_lower)    \n",
    "\n",
    "    input_text_tokenize = word_tokenize(input_text_lower) # Tokenizing string to remove stopwords\n",
    "\n",
    "#     print(input_text_tokenize)\n",
    "\n",
    "\n",
    "\n",
    "    for word in input_text_tokenize:\n",
    "        if word not in stopwords_list:\n",
    "            input_text_remove_stpwrds.append(word) # appending words to list only that words which are not in stopword list\n",
    "\n",
    "#     print(input_text_remove_stpwrds)\n",
    "\n",
    "    tokenize_text = RegexpTokenizer(r'\\w+')\n",
    "    input_text_remove_punct = tokenize_text.tokenize(str(input_text_remove_stpwrds)) # Removing punctuations \n",
    "    \n",
    "    \n",
    "\n",
    "#     print(input_text_remove_punct)\n",
    "    input_text_clean_string = str(input_text_remove_punct)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     print(input_text_clean_string)\n",
    "\n",
    "    input_text_clean_blob = TextBlob(input_text_clean_string) # converting string to Textblob type\n",
    "    \n",
    "    print(f'Cleaned statement: {input_text_clean_blob}')\n",
    "\n",
    "    sentiment = input_text_clean_blob.sentiment  # CALCULATING SENTIMENT SCORE\n",
    "    \n",
    "#     print(sentiment)\n",
    "    if sentiment[0]>0:                              # Defining categry of sentiment score\n",
    "        print('Positive Sentiment')\n",
    "        print(f'Sentiment Score: {sentiment[0]}')\n",
    "    elif sentiment[0]==0:\n",
    "        print('Neutral Sentiment')\n",
    "        print(f'Sentiment Score: {sentiment[0]}')\n",
    "    else:\n",
    "        print('Negative Sentiment')\n",
    "        print(f'Sentiment Score: {sentiment[0]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate your sentiment here by speak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak now....\n",
      "Statement by user: yesterday I have seen a movie that was very good\n",
      "Cleaned statement: ['yesterday', 'seen', 'movie', 'good']\n",
      "Positive Sentiment\n",
      "Sentiment Score: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Testing 1\n",
    "import speech_recognition as sr\n",
    "r1 = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "\n",
    "    print('speak now....')\n",
    "    audio = r1.listen(source)   # taking input as audio from user\n",
    "    \n",
    "    a = r1.recognize_google(audio) # Converting audio into text by recognize_google\n",
    "    print(f\"Statement by user: {a}\")           \n",
    "    \n",
    "Pawan_sentiment_calculator(a)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
